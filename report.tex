\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}

\makeatletter
\def\markboth#1#2{\def\leftmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#1}}%
\def\rightmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#2}}}
\makeatother

\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{url}
\usepackage[norsk,english]{babel}
\usepackage{amsmath}
\usepackage{verbatim}
\usepackage{varioref}
\usepackage{color}
\usepackage{listings}
\usepackage{epsfig, times}

%\usepackage[cmex10]{amsmath}
%\usepackage{algorithmic}
%\usepackage{array}
%\usepackage{mdwmath}
%\usepackage{mdwtab}
%\usepackage[tight,footnotesize]{subfigure}
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{fixltx2e}
%\usepackage{stfloats}

% correct bad hyphenation here
\hyphenation{net-works}


\begin{document}

\title{Implementation of CacheCast\\ in the ns-3 network simulator}

\author{Bekzahan~Kassymbekov,~
        Dag~Henning~Liodden~Sørbø,~
        Kanat~Sarsekeyev,~
        and~Rizwan~Ali~Ahmed}% <-this % stops a space

% \thanks{J. Doe and J. Doe are with Anonymous University.}% <-this % stops a space
% \thanks{Manuscript received April 19, 2005; revised January 11, 2007.}}

% The paper headers
% \markboth{Journal of \LaTeX\ Class Files,~Vol.~6, No.~1, January~2007}%
% {Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}


%%---------------------------------------------------------------------------%%
% make the title area
\maketitle


\begin{abstract}
This paper will introduce and explain the implementation of the CacheCast system in the ns-3 
network simulator. Several aspects of the implementation and views on it will be 
presented. We will let the user know how it should be used in simulations and 
for the developer we present the details of the implementation. Tests and 
evaluations has been performed to prove that the implementation follows the 
design of the CacheCast mechanism. The outcome of this work is an 
independent ns-3 module called \emph{cachecast} which contains all functionality 
to create ns-3 simulations with the CacheCast technique.
\end{abstract}


% \begin{IEEEkeywords}
% IEEEtran, journal, \LaTeX, paper, template.
% \end{IEEEkeywords}


\section{Introduction}
\IEEEPARstart{T}{he} CacheCast system is a new technique which removes redundant 
payload on Internet links. The system is currently implemented in the Linux 
operating system, the Click modular router and partially in the ns-2 network 
simulator. In order to test new techniques and protocols destined for the 
Internet, network simulators are often used. A new network simulator called ns-3 has been developed which
focuses on more accurate modeling of the functionality of a modern network. The 
goal of this work is to implement the CacheCast system in the ns-3 network 
simulator.

The implementation will consist of a ns-3 module which contains the data 
structures and the algorithms for the CacheCast packet handling. The module will 
also contain example scripts and demos to make it easy the see how the module is 
used in ns-3 network simulations.

This document is structured in the following way. In section \ref{s1} we give a brief 
description of the CacheCast system and we follow up which an introduction to 
the ns-3 network simulator in section \ref{s2}. Then we present the API of the 
implementation in section \ref{api}. In section \ref{s4} we dive into the 
details of the implementation and perform an implementation evaluation in 
section \ref{s5}. We give our conclusions in section \ref{s6}. We start now by 
getting to know the CacheCast system design.


\section{The CacheCast system\label{s1}}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{cachecast}
\caption{The packet modification in the CacheCast system}
\label{fig_cachecast}
\end{figure}

CacheCast\cite{srebrny} is a new technique of removing redundant data packets on 
a link. The purpose of CacheCast is to remove as much as possible of the 
overhead when using many unicast connections for the same data over the same 
link. In short, CacheCast only sends the packet payload once over a link 
together with the destination addresses, and then the responsibility lies on the 
router on the link exit to forward the payload to each client. With this 
redundancy removal, CacheCast achieves close to multicast performance when the 
numbers of receivers grow large, without introducing any new protocols into the 
Internet. An overview of the CacheCast packet modification can be seen in figure 
\ref{fig_cachecast}.

As the name implies, CacheCast uses caching to remove the redundant data packets 
from a link. Three main components are needed to make CacheCast work; support 
for CacheCast on the server, a component on the link entry called \emph{Cache 
Management Unit (CMU)} and a component on the link exit called \emph{Cache Store 
Unit (CSU)}. It is important to notice that these components can be divided into 
two groups; server support and network support. These two groups work 
independently of each other. Hence, there is no communication between the server and the 
components in the network. Each CacheCast packet contains a CacheCast header. It 
contains three fields; payload size (\emph{P\_SIZE}), payload id (\emph{P\_ID}) 
and cache index (\emph{INDEX}). The details of these fields will be explained in 
the following sections.

\subsection{Server support}
The use of CacheCast demands that the server is aware of CacheCast support 
in the network, thus a server component is needed. Clients connected to the 
server requesting the same content is served via the CacheCast component. To be 
able to take advantage of CacheCast, data should be sent to many clients at the 
same time. This batching of clients is done by applications using the CacheCast 
support.

The responsibility of the server support is therefore to handle this client 
batching. Currently this handling is done through a system call (\textsf{msend()}) 
implemented in the Linux operating system. The input to this system call is a 
set of connections to clients and the data to be sent. The system call will then 
add the CacheCast header to each packet and mark the packets as CacheCast 
packets. This is done to let the other CacheCast components separate CacheCast 
packets from regular packets.

At last the server sends the packets onto the link in a tight sequential order.  
However, only the first packet contains the payload whereas the other packets are 
truncated. Because of this removal of redundant payload the CacheCast packets 
follow a certain pattern. The first packet contains a header and the data, 
whereas the rest of the packets only contain the headers. This structure is 
called a packet train.

\subsection{Network support}
The network support is implemented on a per link basis and consist of two 
components; the CMU located at the entry of a link, and the CSU located at the exit of 
that same link. This way CacheCast support need not be deployed in the whole 
network. It can be deployed incrementally from the server.

Let us now see how this network support is realised through the CMU and the CSU.
 
\subsubsection{CMU\label{cmu}}
The CMU's responsibility is to remove the redundant payload and manage 
the cache in the CSU. For each payload transfered over the link a unique 
payload ID (P\_ID) is given the payload which identifies, together with 
the source address, the payload uniquely in the Internet. If the CMU 
receives a new CacheCast packet with a P\_ID currently in the cache it 
removes the payload from the packet, adds a CacheCast header and sends the 
truncated packet onto to link. The index field in the CacheCast header identifies 
the payload in the cache in the CSU. If the CMU receives a 
CacheCast packet not currently in the cache it assigns a new P\_ID to the 
payload and inserts this ID into a table. The index of this table entry 
corresponds to the slot in the cache in the CSU where the payload will be 
stored. The CMU then adds the CacheCast header to the packet and sends 
the whole packet onto the link.

\subsubsection{CSU}
The CSU is the component containing the actual cache. The data in the 
first packet of the packet train is stored in a slot in this cache specified by 
the CMU. The job of the CSU is to attach the correct payload to 
the packets containing only headers. The router will process each packet as 
normal IP packets.


\section{The ns-3 network simulator\label{s2}}
The ns-3 simulator\cite{ns-3} is a discrete-event network simulator, in which the simulation core and models are implemented in C++. ns-3 is
built as a library which may be statically or dynamically linked to a C++ main program that defines the simulation
topology and starts the simulator. ns-3 also exports nearly all of its API to Python, allowing Python programs to import
an ¿ns3¿ module in much the same way as the ns-3 library is linked by executables in C++.

It is an open-source project, intended for educational and 
scientific use. Main purpose for usage of this tool is to simulate  different routing protocols, scenarios that accure in different
network. These scenarios and designs of network are implemented by user. ns-2 is a version prior to ns-3, which is a new simulator 
that does not support the ns-2 APIs. ns-3 supports popular network protocols used nowadays. Some models from ns-2 have already been ported 
from ns-2 to ns-3, and some has not yet been implemented in ns-3. 
Version of ns-3 we are using during  our implementation and simulation is ns-3.13. 

\subsection*{Abstractions}
Implementation in ns-3 is based on abstraction, so it can be simplified. 
These abstraction have differences from the network as we know in reality. 
Before we start explaining our implementation of CacheCast in ns-3, it is 
important to understand abstractions and terms that are used in ns-3.

\subsubsection{Node}
In ns-3 devices like host and end-user are represented as abstractions of 
nodes by the class \texttt{Node}. This class provides management of how these 
devices will be represented in simulations. 

\subsubsection{Application}
Application is abstractions of user programs that are suppose to produce activity 
on nodes to be simulated. This is represented by the class \texttt{Application}, 
which provides methods for managing the representations of applications in simulations.

\subsubsection{Channel}
In ns-3, each Node are connected by a connection that are represented by a communication 
channel. This abstraction is represented by class \texttt{Channel}, which provides methods 
for managing communication subnetwork objects and connecting nodes to them.

\subsubsection{NetDevice}
Net device abstraction covers both the software driver and the simulated hardware. 
A net device is  more or less "installed" in a Node in order to enable the Node to communicate 
with other Nodes in the simulation via Channels. Node may be connected to more than one 
Channel via multiple NetDevices. This abstraction is represented by class \texttt{NetDevice} 
which provides management of connections to Node and Channel.

\subsubsection{Topology Helpers}
In a simulated network, connections between Nodes, NetDevices and Channels needs to be 
arranged. NetDevices needs to be attached on Nodes, Node protocol-stack needs to be configured and a 
communication channels need to be defined between NetDevices and so on. Topology helpers are used 
to arrange these attachments as easy as possible on a large scale.

\section{Application programming interface (API)\label{api}} % HOW TO USE IT
We have now talked about the general design of CacheCast and about the details 
of the ns-3 network simulator. In this section we will explain how the CacheCast 
system is used by script authors. bla bla ...


\subsection{Services provided to applications}
Since end-to-end cachecast connections are handled by different sockets, the send procedure requires 
a sequence of send-requests (corresponding to each socket) to transmit packets to all client. A 
multiple-send-request from application layer requires a container of sockets, so the application can 
send packets through / to all sockets in the container. 

Since a such socket container is not supported by transport layer and nor a part of a application-layer, 
we chose to implement a CacheCast Application Programming Interface in the class \texttt{CacheCast}. 
This interface will not only support the socket container, but also systemcall \texttt{Msend()} 
would be provided to the application. This is much more practical than having a static systemcall 
called by the application.

The socket container itself is implemented as a vector of sockets (\texttt{m\_sockets}), which contains 
sockets added by application. In addition to vector \texttt{m\_sockets} we chose to have another 
vector \texttt{m\_failed} to provide the application the knowledge of sockets that failed during the 
msend procedure.

\begin{footnotesize} 
\begin{lstlisting}[language=C,caption = Services provided to application, label=services]

--------------------------------------------------
void AddSocket(Ptr<Socket> socket);
void RemoveSocket(Ptr<Socket> socket);
    
void Merge(CacheCast cc);
   
Iterator Begin (void) const;
Iterator End (void) const;
 
Iterator BeginFailedSockets (void) const;
Iterator EndFailedSockets (void) const;

bool Msend(Ptr<Packet> packet);
--------------------------------------------------
\end{lstlisting}
\end{footnotesize}
In order to maintain the container of sockets, some facilities are provided to applications. 
It is necessary for the application to add or remove sockets in the container. And the possibility 
to merge two or more socket containers might also become handy. It is described in Listing \ref{services}.
 
%Todo moooore
\subsection{Usage of CacheCast API}

In CacheCache, applications stands for creating and binding sockets and CacheCast API
is responsible for maintaining these sockets. When a socket is binded, it is added in the socket 
container simply by using function AddSocket. 

Packet is sent to all socket in the socket container by using function Msend.  
There is no possibility for applications to have a complete overview of which one of socket did 
failed until the Msend function is completed. We have implemented this function 
to return a bool depending on if packet was delivered succesful to all sockets in the container.
If a socket fails, Msend places that socket in a vector for failed sockets and returns false.
The application would then know there is a socket that failed during sending
procedure. An iterator is provided to the application, so it can iterate through the vector 
containing failed sockets. And it is entirely up to the application how failed socket should be treated.
Implementation of Msend is listed later in this document. 

\begin{footnotesize}
\begin{lstlisting}[language=C, caption = Example of usage of CacheCast API]
--------------------------------------------------
std::vector<Address>::const_iterator it;

CacheCast cc;

Ptr<Socket> socket = Socket::CreateSocket 
(GetNode (), TypeId::LookupByName 
("ns3::UdpSocketFactory"));
socket->Bind();
socket->Connect (*it);
cc.AddSocket (socket);

socket = Socket::CreateSocket 
(GetNode (), TypeId::LookupByName 
("ns3::UdpSocketFactory"));
socket->Bind();
socket->Connect (*it);
cc.AddSocket (socket);

Ptr<Packet> packet = Create<Packet> (1472);

if(!cc.Msend(packet)){
  CacheCast::Iterator vItr = cc.BeginFailedSockets();
  while ( vItr != cc.EndFailedSockets() )
  {
    cc.RemoveSocket( (*vItr) );
    vItr++;
  }    
}
--------------------------------------------------
\end{lstlisting}
\end{footnotesize}

\subsection{Helpers}
Helpers are used to setup the Server Unit / CMU and CSU on nodes before channel between these units 
are defined. In both helpers, Install function takes pointer for two nodes as arguments. The only 
difference between these two helpers is that CacheCastServerHelper is intended to be used to define 
characteristics of connections between Serverunit and CSU and CacheCastHelper is used to define 
CMU and CSU. While defining the server node , CacheCastPid is aggregated
 to the object, so it has abillity to wrap around payload id.  

First, CacheCastNetDevices are created for each of these nodes.

%Todo Mer info

Server unit, CMU or CSU are then added to these devices based on type of node that are being 
installed. These devices are then attached to CacheCastChannel before they are added into a 
container of NetDevices.    


\section{Implementation details\label{s4}} % HOW IT WORKS
In the previous section we looked at the implementation of CacheCast in ns-3 
from the user perspective. In this section we will dig deeper into the 
implementation details and look at the implementation from a developer 
perspective. First we explain how the CacheCast packets traverse the nodes and 
the channels in order to get a general overview of how the implementation works. 
Then we look at common data structures used throughout the implementation. At 
last we elaborate on the specific implementation details of each part.

\subsection{General overview}
The implementation of CacheCast in ns-3 (as in the general design of CacheCast) 
consists of three main parts; server support, CMU and CSU. As explained in the 
previous section, to support CacheCast, packets are sent with the 
CacheCast::Msend() function in the ns-3 applications on the server node. Then 
the packets traverse the network layers and is intercepted by the CacheCastNetDevice. In 
this CacheCastNetDevice a CacheCastServerUnit is installed which adds a 
CacheCastHeader to the packets and truncates packets with redundant payload. The 
packets then traverse the channel and is received by a CacheCastNetDevice 
on the other end. In this CacheCastNetDevice a CacheStoreUnit is 
installed which adds payload to the truncated packets and remove the 
CacheCastHeader. The packets are then handled as normal IP packets in the node. 
If the packet is destined for another node, it is again intercepted by a 
CacheCastNetDevice in which a CacheManagementUnit is installed. This unit adds 
the CacheCastHeader to the packet and truncates packets with redundant payload. 
The packets then traverse another channel and is received by another
CacheCastNetDevice with a CacheStoreUnit installed. This process is continued 
for each node supporting CacheCast on the packet's path to its destination. An 
graphical overview of this structure can be seen in figure \ref{fig_overview}.

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{overview}
\caption{The structure of the CacheCast system in ns-3}
\label{fig_overview}
\end{figure}


\subsection{Common data structures and classes}
In this section we explain the common data structures used by the different 
parts of the ns-3 implementation of CacheCast.

\subsubsection{CacheCast header}
The CacheCast header is represented in ns-3 as a class named CacheCastHeader. 
This class is derived from the general ns3::Header class. The class contains the 
same members as the header described in the design of CacheCast, namely payload 
ID, payload size and index. An overview of the %CacheCast related elements of the 
CacheCastHeader is given in the listing below.

\begin{footnotesize}
% -------------- WIDTH ----------------------------]
\begin{lstlisting}[language=C]
--------------------------------------------------
#include "ns3/header.h"

namespace ns3 {
class CacheCastHeader : public Header
{
public:
  CacheCastHeader ();
  CacheCastHeader (uint32_t payloadId, 
    uint16_t payloadSize, uint32_t index);
  uint32_t GetPayloadId (void) const;
  uint16_t GetPayloadSize (void) const;
  uint32_t GetIndex (void) const;
  void SetPayloadId (uint32_t payloadId);
  void SetPayloadSize (uint16_t payloadSize);
  void SetIndex (uint32_t index);

  static TypeId GetTypeId (void);
  TypeId GetInstanceTypeId (void) const;
  void Print (std::ostream &os) const;
  uint32_t GetSerializedSize (void) const;
  void Serialize (Buffer::Iterator start) const;
  uint32_t Deserialize (Buffer::Iterator start);
private:
  uint32_t m_payloadId;
  uint16_t m_payloadSize;
  uint32_t m_index;
};
}
--------------------------------------------------
\end{lstlisting}
\end{footnotesize}


\subsubsection{CacheCast packet tag}
In ns-3 one have the possibility to add packet tags to packets in order to store 
information on a packet level. In the implementation of CacheCast we use packet 
tags to store CacheCast related values when the packet is processed in a node.  
Since the packets should be processed on the nodes as normal IP packets, the 
CacheCast header has to be removed, so this is the main reason for introducing a 
CacheCastTag. The contents of the CacheCast tag is the payload ID and the 
payload size. These are necessary for the CMU and server unit in order to 
uniquely identify CacheCast packets and handle them correctly. In an 
implementation in a normal router, metadata attributes is added to the CacheCast 
packets while they are being processed in the router. The CacheCastTag simulates 
this metadata but the CacheCastTag is not removed from the packet when the 
packets has been processed by a router node (as the metadata would in a normal 
router). There is no problem with this design choice since packet tags do not 
affect how the packets it being transmitted on a link, and because the payload 
ID and payload size is the same in the whole lifetime of a CacheCast packet. The 
CacheCastTag is added to the packets by the \textsf{CacheCast::Msend()} function 
(see section \ref{api_impl}).

\subsubsection{CacheCastUnit}
The CacheCastUnit class is an abstract base class which should be derived from 
in order to support different packet handling schemes in CacheCast. This class 
contains only one CacheCast related function named \textsf{virtual bool 
HandlePacket (Ptr<Packet> p)}. This function takes a pointer to a packet which 
it can modify. The derived classes is supposed to override this function. There 
are currently three derived classes from the CacheCastUnit base class; 
CacheCastServerUnit, CacheManagementUnit and CacheStoreUnit. These classed will 
be explained later in this document.

\subsubsection{CacheCastNetDevice}
In the ns-3 network simulator the abstraction of the physical and the data link 
layer is modeled by a NetDevice. This NetDevice receives a packet from the 
network layer, adds link layer headers, and puts the packet onto the channel. In 
order to handle CacheCast packets on the link level we have chosen to create a 
new NetDevice called CacheCastNetDevice. This NetDevice is based on 
the PointToPointNetDevice. In the first attempt of creating this NetDevice we 
tried to make CacheCastNetDevice a derived class of the PointToPointNetDevice. 
This proved difficult due to the design of the PointToPointNetDevice. There was 
no way to get to the packet after the transmission queue and before it was 
transmitted onto the link, which is crucial for the CacheCast technique. Because 
of this we chose to copy much of the code from PointToPointNetDevice and adapt 
it to the CacheCast scenario. Since CacheCast is only supported on 
point-to-point links the CacheCastNetDevice need not be generalized into 
arbitrary link level technologies.

The CacheCastNetDevice is used both on the server and on nodes and it is used 
together with the ServerUnit, the CMU and the CSU. To support these different 
scenarios we have added a senderUnit and a receiverUnit object to the class. 
These objects are derived from the CacheCastUnit class so their purpose is to 
modify packets. The main idea of CacheCast is to intercept the packets before 
they are transmitted onto the link to remove redundant payload. In our 
implementation this interception is done in the 
CacheCastNetDevice::TransmitStart() function. The packets need to be intercepted 
also on the receiver side, and this is done in CacheCastNetDevice::Receive(). In 
these functions the HandlePacket() function of the senderUnit and receiverUnit 
is called, respectively. So this is where the actual CacheCast packet 
modification happens. More will be said in the following sections about how this 
packet modification is done.

In order to have a channel to connect to the new CacheCastNetDevice we had to 
create an adapted version of the PointToPointChannel named CacheCastChannel. The 
reason for this class is to support the CacheCastNetDevice. In ns-3 the design 
of the NetDevice and the Channel is closely related. So certain types of 
Channels can only be used with certain types of NetDevices. This was the only reason 
why we had to create a separate CacheCastChannel. No CacheCast 
related packet handling is done in the CacheCastChannel.

Now we have looked into the common data structures used in our 
implementation. Let us in the following sections go more into detail of the 
actual packet handling mechanisms of the CacheCast system. First we take a look 
into the server part and then we continue with the networking part of the 
implementation.


\subsection{Server support}
The CacheCast system relies on support from the server in order to remove 
redundant payload in the network. This server support should send all packets 
sequentially onto the link and truncate all packets beside the first one.

The general design of the CacheCast server support consists mainly of two parts; 
the programming interface to the applications, explained in section \ref{api}, and the underlying packet handling 
mechanism. The implementation in ns-3 closely resembles this division. The 
implementation details of the API exposed to the applications is discussed in 
the next section while the underlying handling of packets is discussed in 
section \ref{serverunit}.


\subsubsection{Details of the API implementation\label{api_impl}}

%Todo mer om API

CacheCast::Msend function takes pointer to a packet as an argument which is generated by the 
application. This functions returns a boolean value depended on packet delivery to all 
sockets in socket container are successful or not. 

Before sending packet to socket, payload-id must be generated and added to the packet as a 
packet-tag, which is done along with the size of the packet. 
CacheCastPid::CalculateNewPayloadId() is called to generate the payload-id. 
Usually this id is increased if packets are sent continously. If more than 1 second 
has passed since last packetrain, the payload-id is wrapped around to 0.

Each socket in socket container is tested if it is a cachecast-supporting socket or not, 
since in CacheCast UDP and DCCP are only supported protocols in the transport layer. 
(DCCP is not implemented in our solution, since it is not yet supported in ns-3.) 

\begin{footnotesize}
% -------------- WIDTH ----------------------------]
\begin{lstlisting}[language=C,caption = Function Msend()]
--------------------------------------------------
bool 
CacheCast::Msend (Ptr<Packet> packet)
{

  bool successful = true;
  std::vector<Ptr <Socket> >::iterator socket;

  if (m_sockets.size() == 0)
    return true;

  Ptr<CacheCastPid> pid = m_sockets[0]->GetNode ()
  ->GetObject<CacheCastPid> ();
  
  NS_ASSERT_MSG (pid, 
  "A CacheCast server must have a CacheCastPid object");
  
  uint32_t payloadId = pid->CalculateNewPayloadId ();

  for(socket = m_sockets.begin(); 
  socket != m_sockets.end(); ++socket)
  {        
    // if DCCP gets supported handle it also
    NS_ASSERT_MSG ((*socket)->GetSocketType () 
    == Socket::NS3_SOCK_DGRAM,
    
    "CacheCast supports only UDP sockets");
    
    Ptr<Packet> p = packet->Copy (); 

    CacheCastTag tag (payloadId, p->GetSize ());
    p->AddPacketTag (tag);        

    if((*socket)->Send(p) < 0)
    {
      successful = false;
      SetFailedSocket (socket_index);
    }
  }

  return successful; 
}
--------------------------------------------------
\end{lstlisting}
\end{footnotesize}


\subsubsection{Underlying packet handling mechanism\label{serverunit}}
The tasks of the underlying packet handling mechanism in a CacheCast supported 
server is to ensure that the packets are put onto the link in a tight chain, to 
truncate packets with redundant payload and to add the CacheCast header to each 
packet. In the Linux implementation of CacheCast this mechanism is handled by a 
kernel module located between the network layer and the link layer. As 
previously explained we have chosen to create a new CacheCastNetDevice in which 
we can install different packet handling mechanisms. This is where the CacheCast 
packet modification will happen.

On the server an object of a class CacheCastServerUnit is added as a senderUnit 
to each CacheCastNetDevice. The CacheCastServerUnit::HandlePacket() function 
does the actual packet modification and its content is listed in listing 
\ref{ccsu} below.

\begin{lstlisting}[language=C, showstringspaces=false, basicstyle=\footnotesize, 
caption=HandlePacket() function in CacheCastServerUnit, frame=tb, label=ccsu]
--------------------------------------------------
bool
CacheCastServerUnit::HandlePacket (Ptr<Packet> p)
{
  CacheCastTag tag;
  bool hasTag = p->RemovePacketTag (tag);
  NS_ASSERT_MSG (hasTag, "No CacheCast packet tag");

  CacheCastHeader cch (tag.GetPayloadId (),
    tag.GetPayloadSize (), 0);

  /* Invalidate the current payload ID
     after one second */
  if (Simulator::Now ().GetSeconds () - m_timeStamp
    > 1.0) {
    NS_LOG_DEBUG ("CacheCast server table 
        invalidated");
    m_invalid = true;
    m_timeStamp = Simulator::Now ().GetSeconds ();
  }

  if (m_payloadId == tag.GetPayloadId ()
      && !m_invalid) {
    // remove payload
    p->RemoveAtEnd (tag.GetPayloadSize ());
    cch.SetPayloadSize (0);
  } else {
    // new payload ID
    m_payloadId = tag.GetPayloadId ();
    m_invalid = false;
  }

  p->AddHeader (cch);

  return true;
}
--------------------------------------------------
\end{lstlisting}

In the code of CacheCastServerUnit::HandlePacket() we first check if the payload 
has been in the table for more than 1 second, and if it has we invalidate this payload ID from the 
table. The reason for doing this is to support wrapping of payload IDs. The 
design of CacheCast specifies that a specific payload ID should be invalidated 
if it has been present in a table for 1 second or more. The rest of the code 
does the necessary modifications to the packet. If the packet's payload ID is not present in the table it 
is added and no further changes are done to the packet payload. If a payload ID 
is present in the table the payload is removed from the packet and the payload 
size field in the CacheCastHeader is set to 0. At last the CacheCastHeader is 
added to the packet. The HandlePacket() function returns control back to the 
CacheCastNetDevice::TransmitStart() function which continues to transmit the 
packet onto the channel. The transmission time on the channel is calculated 
based on the size of the modified packet.

The design of CacheCast demands that the packets forming a packet train is put 
in a tight sequential order on the link. In order to obtain a continuous packet 
train all packets with the same payload should be transmitted in one batch onto 
the link. In the implementation of CacheCast in Linux this is handled by a 
separate packet queue in the CacheCast kernel module to overcome the issue of 
the multiprogramming nature of modern operating systems. In ns-3 all code is executed 
in sequential order with no interruption. Also computing time on the nodes is 
not modeled in ns-3. Thus in our implementation we do not need to batch the 
packets at link layer level. The batching of sockets done in the application domain is 
sufficient enough to form continuous packet trains.

The fact that packets with the same payload ID 
are sent as a batch onto the channel also imply that the table of payload IDs on 
the server need only contain one element. In the code we don't even have a 
table, the payload ID is stored as a single variable. This fact also implies that the CSU on 
the other side of the channel from the server, need only have one slot in its 
cache. Therefore we always use an index of 0 in the CacheCastHeader appended to 
the packets.


\subsection{Network support}
In the previous section we described the server support implementation of 
CacheCast in ns-3. In this section we take a look at how the network support 
(CMU and CSU) is implemented. Due to time issues and test problems there are two 
implementations of the network support presented in this section.

\subsubsection{Network implementation (Lancaster version)}


\subsubsection{Network implementation (Oslo version)}



\section{Evaluation\label{s5}}
We have in the previous sections looked into both the general design of 
CacheCast and how the system is implemented in the ns-3 network simulator. In 
this section will will evaluate our implementation to make sure that it is 
functioning correctly. First we test the server part and the network part of the 
implementation. Then we construct integration tests to evaluate the 
network implementation together with the server support to make sure that the 
two parts of the CacheCast module integrates well with each other.

Before we start with our test cases we introduce a useful feature when doing 
evaluations. In ns-3 there is a concept called trace sources. A trace source is 
basically a list of function pointers. At some point in the code the trace 
source fires, which means that all connected functions are called. A script 
writer is able to connect to different trace sources to get status information 
during the simulation. In the CacheCast module there are currently four trace 
sources called \emph{CcPreSend}, \emph{CcPostSend}, \emph{CcPreRecv} and 
\emph{CcPostRecv}, which fires before the CMU, after the CMU, before the CSU and 
after the CSU, respectively.


\subsection{Server support evaluation}
The CacheCast design requires server support to handle client batching and
to send packets onto the link in a tight sequential order in a structure of
a packet train. This is tested by setting up a topology with nodes.
In this topology, dataRate value for the server node is set to 2Mbps and 
delay is set to be 2ms in the channel between server node (n0) and cachecast node (n2).
Payload size of packet set to 1000, in addition to header size which is set to 40.

By simulating our simulation we see following result at receiver unit of cachecast node. 

\begin{footnotesize}
% -------------- WIDTH ----------------------------]
\begin{lstlisting}[language=C,caption = Function Msend() frame=tb]
Time    Size
------------ 
2.00616 1040
2.00632 40
2.00648 40
2.00664 40
\end{lstlisting}
\end{footnotesize}

As we can see, the first packet arrives with expected delay and is complete.   
And following packets are arriving as a packet train with with a short timeline and are in 
size of the header size. 


\subsection{Network support evaluation}


\subsection{CacheCast module evaluation\label{eval_mod}}


\section{Conclusion\label{s6}}
The conclusion goes here.

what is made:
    demos in example dir

\subsection{Future work}
The current implementation of CacheCast in ns-3 contains the features explained 
throughout this paper. This last section explains some of the work that might be 
done to the CacheCast module in the future.

1) The implementation of CacheCast in Linux supports both the UDP and DCCP 
transport protocols. In ns-3 there is currently no implementation of the DCCP 
protocol. If DCCP support is added to ns-3 in the future, the CacheCast 
module could be adapted to support this transport protocol.

2) Our implementation uses the PointToPointNetDevice as a basis for the 
CacheCastNetDevice. The PointToPointNetDevice does not model an ethernet link, 
just a general point-to-point link. To further enhance the realism in the 
CacheCast module, the CacheCastNetDevice should support ethernet links. 
In version 3.13 of ns-3 (which we rely on) does not have support for switched 
ethernet, but this support is currently being implemented in ns-3. Hence, support for 
ethernet links may be easily added to the CacheCast modules in the future.

3) Lastly, there is one issue which is not handle by current implementations of 
CacheCast. This issue arises most probably only with cache sizes with room for 
only one packet. First a CacheCast packet is sent and cached on the CSU. Then no 
packets are sent for 1 second. Then a new packet train is sent with the same 
payload ID and index as the previous packet. Then the first packet in the packet train is 
lost on the link. Then when the rest of the packets are processed by the CSU, 
the wrong payload is added to the packets. This issue might be easily solved by 
storing a time stamp together with the payload ID in the CSU.


% \appendices
% \section{Proof of the First Zonklar Equation}
% Appendix one text goes here.
% 
% % you can choose not to have a title for an appendix
% % if you want by leaving the argument blank
% \section{}
% Appendix two text goes here.


\section*{Acknowledgment}
The authors would like to thank their always positive and helpful supervisor Piotr 
Srebrny for useful guidelines and input in time of need.

\bibliography{library}
\bibliographystyle{IEEEtran}

\section*{Contributions}

\begin{tabular}{|l||p{5.3cm}|}
\hline
Bekzahan & \textbf{Report:}\\
Kassymbekov & \textbf{Report:}\\
\hline
Dag~Henning & \textbf{Report:}\\
Liodden~Sørbø & The CacheCast system\\
& \emph{Implementation details:}\\
& -~General overview\\
& -~Common data structures and classes\\
& ~~\emph{Server support:}\\
& ~~-~Underlying packet handling mechanism\\
& ~~\emph{Network support (Oslo version):}\\
& ~~-~CMU\\
& -~CacheCast module evaluation\\
& -~Future work\\
& \textbf{Implementation:}\\
& -~CacheCastHeader\\
& -~CacheCastNetDevice\\
& -~CacheCastTag\\
& -~CacheManagementUnit (Oslo version)\\
& -~CacheCastServerUnit\\
& -~CacheCast helpers\\
& -~CacheCast examples\\
\hline
Kanat & ...\\
Sarsekeyev & ...\\
\hline
Rizwan & \textbf{Report:}\\
Ali~Ahmed & The ns-3 network simulator\\
& -~Application programming interface (API)\\
& \emph{Implementation details:}\\
& ~~\emph{Server support:}\\
& ~~-~Details of the API implementation\\
& ~~\emph{Network support (Oslo version):}\\
& ~~-~CSU\\
& -~Server support evaluation\\
& \textbf{Implementation:}\\
& -~CacheCast container\\
& -~Msend() function\\
& -~CacheStoreUnit (Oslo version)\\
\hline
\end{tabular}


%%---------------------------------------------------------------------------%%
\end{document}


% EXAMPLES

%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}

